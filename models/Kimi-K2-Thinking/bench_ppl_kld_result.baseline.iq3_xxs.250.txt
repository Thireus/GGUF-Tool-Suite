ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 4 CUDA devices:
  Device 0: NVIDIA RTX PRO 6000 Blackwell Workstation Edition, compute capability 12.0, VMM: yes, VRAM: 97886 MiB
  Device 1: NVIDIA RTX PRO 6000 Blackwell Workstation Edition, compute capability 12.0, VMM: yes, VRAM: 97886 MiB
  Device 2: NVIDIA RTX PRO 6000 Blackwell Workstation Edition, compute capability 12.0, VMM: yes, VRAM: 97886 MiB
  Device 3: NVIDIA GeForce RTX 5090, compute capability 12.0, VMM: yes, VRAM: 32606 MiB
main: build = 1 (bc2b292)
main: built with MSVC 19.44.35221.0 for 
main: seed  = 1337
CUDA0: using device CUDA0 - 95288 MiB free
CUDA1: using device CUDA1 - 95288 MiB free
CUDA2: using device CUDA2 - 95288 MiB free
CUDA3: using device CUDA3 - 30841 MiB free
llama_model_loader: max stdio successfully set to 2048
llama_model_loader: additional 1096 GGUFs metadata loaded.
llama_model_loader: loaded meta data with 49 key-value pairs and 1096 tensors from ./Kimi-K2-Thinking-THIREUS-BF16-SPECIAL_TENSOR-00001-of-01097.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = deepseek2
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                         general.size_label str              = 384x14B
llama_model_loader: - kv   3:                            general.license str              = other
llama_model_loader: - kv   4:                       general.license.name str              = modified-mit
llama_model_loader: - kv   5:                      deepseek2.block_count u32              = 61
llama_model_loader: - kv   6:                   deepseek2.context_length u32              = 262144
llama_model_loader: - kv   7:                 deepseek2.embedding_length u32              = 7168
llama_model_loader: - kv   8:              deepseek2.feed_forward_length u32              = 18432
llama_model_loader: - kv   9:             deepseek2.attention.head_count u32              = 64
llama_model_loader: - kv  10:          deepseek2.attention.head_count_kv u32              = 1
llama_model_loader: - kv  11:                   deepseek2.rope.freq_base f32              = 50000.000000
llama_model_loader: - kv  12: deepseek2.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  13:                deepseek2.expert_used_count u32              = 8
llama_model_loader: - kv  14:               deepseek2.expert_group_count u32              = 1
llama_model_loader: - kv  15:          deepseek2.expert_group_used_count u32              = 1
llama_model_loader: - kv  16:               deepseek2.expert_gating_func u32              = 2
llama_model_loader: - kv  17:                          general.file_type u32              = 32
llama_model_loader: - kv  18:        deepseek2.leading_dense_block_count u32              = 1
llama_model_loader: - kv  19:                       deepseek2.vocab_size u32              = 163840
llama_model_loader: - kv  20:            deepseek2.attention.q_lora_rank u32              = 1536
llama_model_loader: - kv  21:           deepseek2.attention.kv_lora_rank u32              = 512
llama_model_loader: - kv  22:             deepseek2.attention.key_length u32              = 576
llama_model_loader: - kv  23:           deepseek2.attention.value_length u32              = 512
llama_model_loader: - kv  24:         deepseek2.attention.key_length_mla u32              = 192
llama_model_loader: - kv  25:       deepseek2.attention.value_length_mla u32              = 128
llama_model_loader: - kv  26:       deepseek2.expert_feed_forward_length u32              = 2048
llama_model_loader: - kv  27:                     deepseek2.expert_count u32              = 384
llama_model_loader: - kv  28:              deepseek2.expert_shared_count u32              = 1
llama_model_loader: - kv  29:             deepseek2.expert_weights_scale f32              = 2.827000
llama_model_loader: - kv  30:              deepseek2.expert_weights_norm bool             = true
llama_model_loader: - kv  31:             deepseek2.rope.dimension_count u32              = 64
llama_model_loader: - kv  32:                deepseek2.rope.scaling.type str              = yarn
llama_model_loader: - kv  33:              deepseek2.rope.scaling.factor f32              = 64.000000
llama_model_loader: - kv  34: deepseek2.rope.scaling.original_context_length u32              = 4096
llama_model_loader: - kv  35: deepseek2.rope.scaling.yarn_log_multiplier f32              = 0.100000
llama_model_loader: - kv  36:               general.quantization_version u32              = 2
llama_model_loader: - kv  37:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  38:                         tokenizer.ggml.pre str              = kimi-k2
llama_model_loader: - kv  39:                      tokenizer.ggml.tokens arr[str,163840]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  40:                  tokenizer.ggml.token_type arr[i32,163840]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  41:                      tokenizer.ggml.merges arr[str,163328]  = ["Ġ Ġ", "ĠĠ ĠĠ", "Ġ t", "i n",...
llama_model_loader: - kv  42:                tokenizer.ggml.bos_token_id u32              = 163584
llama_model_loader: - kv  43:                tokenizer.ggml.eos_token_id u32              = 163586
llama_model_loader: - kv  44:            tokenizer.ggml.padding_token_id u32              = 163839
llama_model_loader: - kv  45:                    tokenizer.chat_template str              = {%- macro render_content(msg) -%}\n   ...
llama_model_loader: - kv  46:                                   split.no u16              = 0
llama_model_loader: - kv  47:                                split.count u16              = 1097
llama_model_loader: - kv  48:                        split.tensors.count i32              = 1096
llama_model_loader: - type  f32:  365 tensors
llama_model_loader: - type iq3_xxs:  670 tensors
llama_model_loader: - type iq4_nl:   61 tensors
load: printing all EOG tokens:
load:   - 163586 ('<|im_end|>')
load: special tokens cache size = 256
load: token to piece cache size = 1.0606 MB
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = deepseek2
llm_load_print_meta: n_ctx_train      = 262144
llm_load_print_meta: n_embd           = 7168
llm_load_print_meta: n_layer          = 61
llm_load_print_meta: n_head           = 64
llm_load_print_meta: n_head_kv        = 64
llm_load_print_meta: n_rot            = 64
llm_load_print_meta: n_swa            = 0
llm_load_print_meta: n_swa_pattern    = 1
llm_load_print_meta: n_embd_head_k    = 192
llm_load_print_meta: n_embd_head_v    = 128
llm_load_print_meta: n_gqa            = 1
llm_load_print_meta: n_embd_k_gqa     = 12288
llm_load_print_meta: n_embd_v_gqa     = 8192
llm_load_print_meta: f_norm_eps       = 0.0e+00
llm_load_print_meta: f_norm_rms_eps   = 1.0e-05
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: f_logit_scale    = 0.0e+00
llm_load_print_meta: n_ff             = 18432
llm_load_print_meta: n_expert         = 384
llm_load_print_meta: n_expert_used    = 8
llm_load_print_meta: causal attn      = 1
llm_load_print_meta: pooling type     = 0
llm_load_print_meta: rope type        = 0
llm_load_print_meta: rope scaling     = yarn
llm_load_print_meta: freq_base_train  = 50000.0
llm_load_print_meta: freq_scale_train = 0.015625
llm_load_print_meta: n_ctx_orig_yarn  = 4096
llm_load_print_meta: rope_finetuned   = unknown
llm_load_print_meta: ssm_d_conv       = 0
llm_load_print_meta: ssm_d_inner      = 0
llm_load_print_meta: ssm_d_state      = 0
llm_load_print_meta: ssm_dt_rank      = 0
llm_load_print_meta: model type       = 671B
llm_load_print_meta: model ftype      = BF16
llm_load_print_meta: model params     = 1.026 T
llm_load_print_meta: model size       = 366.540 GiB (3.068 BPW) 
llm_load_print_meta: repeating layers = 365.702 GiB (3.068 BPW, 1024.059 B parameters)
llm_load_print_meta: general.name     = n/a
llm_load_print_meta: n_layer_dense_lead   = 1
llm_load_print_meta: n_lora_q             = 1536
llm_load_print_meta: n_lora_kv            = 512
llm_load_print_meta: n_ff_exp             = 2048
llm_load_print_meta: n_expert_shared      = 1
llm_load_print_meta: expert_weights_scale = 2.8
llm_load_print_meta: expert_weights_norm  = 1
llm_load_print_meta: expert_gating_func   = sigmoid
llm_load_print_meta: rope_yarn_log_mul    = 0.1000
print_info: vocab type       = BPE
print_info: n_vocab          = 163840
print_info: n_merges         = 163328
print_info: BOS token        = 163584 '[BOS]'
print_info: EOS token        = 163586 '<|im_end|>'
print_info: EOT token        = 163586 '<|im_end|>'
print_info: PAD token        = 163839 '[PAD]'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 163586 '<|im_end|>'
print_info: max token length = 512
llm_load_tensors: ggml ctx size =   13.37 MiB
Tensor blk.0.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.0.ffn_gate.weight buffer type overriden to CUDA0
Tensor blk.0.ffn_down.weight buffer type overriden to CUDA0
Tensor blk.0.ffn_up.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.11.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.11.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.11.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.11.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.11.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.11.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.11.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.11.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.12.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.12.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.12.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.12.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.12.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.12.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.12.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.12.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.13.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.13.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.13.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.13.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.13.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.13.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.13.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.13.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.14.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.21.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.21.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.21.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.21.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.21.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.21.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.21.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.21.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.22.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.22.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.22.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.22.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.22.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.22.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.22.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.22.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.23.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.23.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.23.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.23.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.23.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.23.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.23.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.23.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.24.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.24.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.24.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.24.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.24.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.24.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.24.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.24.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.25.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.25.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.25.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.25.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.25.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.25.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.25.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.25.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.26.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.26.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.26.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.26.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.26.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.26.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.26.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.26.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.27.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.27.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.27.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.27.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.27.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.27.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.27.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.27.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.28.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.31.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.31.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.31.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.31.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.31.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.31.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.31.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.31.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.32.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.32.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.32.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.32.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.32.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.32.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.32.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.32.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.33.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.33.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.33.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.33.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.33.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.33.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.33.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.33.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.34.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.34.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.34.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.34.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.34.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.34.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.34.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.34.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.35.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.35.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.35.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.35.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.35.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.35.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.35.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.35.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.36.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.36.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.36.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.36.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.36.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.36.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.36.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.36.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.37.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.37.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.37.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.37.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.37.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.37.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.37.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.37.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.38.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.38.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.38.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.38.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.38.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.38.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.38.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.38.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.39.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.39.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.39.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.39.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.39.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.39.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.39.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.39.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.40.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.40.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.40.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.40.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.40.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.40.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.40.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.40.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.41.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.41.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.41.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.41.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.41.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.41.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.41.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.41.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.42.ffn_norm.weight buffer type overriden to CUDA3
Tensor blk.42.ffn_gate_inp.weight buffer type overriden to CUDA3
Tensor blk.42.ffn_gate_exps.weight buffer type overriden to CUDA3
Tensor blk.42.ffn_down_exps.weight buffer type overriden to CUDA3
Tensor blk.42.ffn_up_exps.weight buffer type overriden to CUDA3
Tensor blk.42.ffn_gate_shexp.weight buffer type overriden to CUDA3
Tensor blk.42.ffn_down_shexp.weight buffer type overriden to CUDA3
Tensor blk.42.ffn_up_shexp.weight buffer type overriden to CUDA3
Tensor blk.43.ffn_norm.weight buffer type overriden to CUDA3
Tensor blk.43.ffn_gate_inp.weight buffer type overriden to CUDA3
Tensor blk.43.ffn_gate_exps.weight buffer type overriden to CUDA3
Tensor blk.43.ffn_down_exps.weight buffer type overriden to CUDA3
Tensor blk.43.ffn_up_exps.weight buffer type overriden to CUDA3
Tensor blk.43.ffn_gate_shexp.weight buffer type overriden to CUDA3
Tensor blk.43.ffn_down_shexp.weight buffer type overriden to CUDA3
Tensor blk.43.ffn_up_shexp.weight buffer type overriden to CUDA3
Tensor blk.44.ffn_norm.weight buffer type overriden to CUDA3
Tensor blk.44.ffn_gate_inp.weight buffer type overriden to CUDA3
Tensor blk.44.ffn_gate_exps.weight buffer type overriden to CUDA3
Tensor blk.44.ffn_down_exps.weight buffer type overriden to CUDA3
Tensor blk.44.ffn_up_exps.weight buffer type overriden to CUDA3
Tensor blk.44.ffn_gate_shexp.weight buffer type overriden to CUDA3
Tensor blk.44.ffn_down_shexp.weight buffer type overriden to CUDA3
Tensor blk.44.ffn_up_shexp.weight buffer type overriden to CUDA3
Tensor blk.45.ffn_norm.weight buffer type overriden to CUDA3
Tensor blk.45.ffn_gate_inp.weight buffer type overriden to CUDA3
Tensor blk.45.ffn_gate_exps.weight buffer type overriden to CUDA3
Tensor blk.45.ffn_down_exps.weight buffer type overriden to CUDA3
Tensor blk.45.ffn_up_exps.weight buffer type overriden to CUDA3
Tensor blk.45.ffn_gate_shexp.weight buffer type overriden to CUDA3
Tensor blk.45.ffn_down_shexp.weight buffer type overriden to CUDA3
Tensor blk.45.ffn_up_shexp.weight buffer type overriden to CUDA3
Tensor blk.46.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.46.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.46.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.47.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.47.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.47.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.48.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.48.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.48.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.49.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.49.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.49.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.50.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.50.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.50.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.51.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.51.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.51.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.52.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.52.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.52.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.53.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.53.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.53.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.54.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.54.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.54.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.55.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.55.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.55.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.56.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.56.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.56.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.57.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.57.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.57.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.58.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.58.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.58.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.59.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.59.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.59.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.60.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.60.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.60.ffn_up_exps.weight buffer type overriden to CPU
llm_load_tensors: offloading 61 repeating layers to GPU
llm_load_tensors: offloading non-repeating layers to GPU
llm_load_tensors: offloaded 62/62 layers to GPU
llm_load_tensors:        CPU buffer size = 92610.00 MiB
llm_load_tensors:  CUDA_Host buffer size =   428.75 MiB
llm_load_tensors:      CUDA0 buffer size = 81468.39 MiB
llm_load_tensors:      CUDA1 buffer size = 87524.27 MiB
llm_load_tensors:      CUDA2 buffer size = 87752.65 MiB
llm_load_tensors:      CUDA3 buffer size = 25552.59 MiB
....................................................................................................
============ llm_prepare_mla: need to compute 61 wkv_b tensors
================= Adjusted mainline llama.cpp MLA tensors to ik_llama.cpp
Computed blk.0.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.1.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.2.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.3.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.4.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.5.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.6.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.7.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.8.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.9.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.10.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.11.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.12.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.13.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.14.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.15.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.16.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.17.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.18.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.19.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.20.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.21.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.22.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.23.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.24.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.25.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.26.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.27.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.28.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.29.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.30.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.31.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.32.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.33.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.34.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.35.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.36.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.37.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.38.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.39.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.40.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.41.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.42.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.43.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.44.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.45.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.46.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.47.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.48.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.49.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.50.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.51.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.52.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.53.attn_kv_b.weight as 512 x 16384 and storellama_new_context_with_model: n_ctx         = 4096
llama_new_context_with_model: n_batch       = 4096
llama_new_context_with_model: n_ubatch      = 4096
llama_new_context_with_model: flash_attn    = 1
llama_new_context_with_model: mla_attn      = 3
llama_new_context_with_model: attn_max_b    = 1024
llama_new_context_with_model: fused_moe     = 1
llama_new_context_with_model: grouped er    = 0
llama_new_context_with_model: fused_up_gate = 1
llama_new_context_with_model: fused_mmad    = 1
llama_new_context_with_model: rope_cache    = 0
llama_new_context_with_model: graph_reuse   = 0
llama_new_context_with_model: k_cache_hadam = 0
llama_new_context_with_model: ser           = -1, 0
llama_new_context_with_model: freq_base     = 50000.0
llama_new_context_with_model: freq_scale    = 0.015625
llama_kv_cache_init:      CUDA0 KV buffer size =    85.50 MiB
llama_kv_cache_init:      CUDA1 KV buffer size =    85.50 MiB
llama_kv_cache_init:      CUDA2 KV buffer size =    81.00 MiB
llama_kv_cache_init:      CUDA3 KV buffer size =    22.50 MiB
llama_new_context_with_model: KV self size  =  274.50 MiB, c^KV (f16):  274.50 MiB, kv^T: not used
llama_new_context_with_model:  CUDA_Host  output buffer size =     5.00 MiB
llama_new_context_with_model:      CUDA0 compute buffer size =  4490.00 MiB
llama_new_context_with_model:      CUDA1 compute buffer size =  1638.14 MiB
llama_new_context_with_model:      CUDA2 compute buffer size =  1638.14 MiB
llama_new_context_with_model:      CUDA3 compute buffer size =  2672.00 MiB
llama_new_context_with_model:  CUDA_Host compute buffer size =   144.05 MiB
llama_new_context_with_model: graph nodes  = 3282
llama_new_context_with_model: graph splits = 122
XXXXXXXXXXXXXXXXXXXXX Setting only active experts offload

system_info: n_threads = 36 / 36 | AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | 
perplexity: saving all logits to bench_kld_result.baseline.iq3_xxs.250.bin
perplexity: tokenizing the input ..
perplexity: tokenization took 1041.1 ms
perplexity: calculating perplexity over 250 chunks, n_ctx=512, batch_size=4096, n_seq=8
perplexity: 25.21 seconds per pass - ETA 13.12 minutes
d in buffer CUDA2
Computed blk.54.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.55.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.56.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA3
Computed blk.57.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA3
Computed blk.58.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA3
Computed blk.59.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA3
Computed blk.60.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA3
[1]76.1363,[2]14.1535,[3]7.0324,[4]4.3298,[5]3.3318,[6]2.7737,[7]2.4143,[8]2.1874,[9]2.1285,[10]2.0704,[11]2.0898,[12]2.3153,[13]2.4028,[14]2.3852,[15]2.2537,[16]2.1498,[17]2.0606,[18]1.9972,[19]1.9301,[20]1.8820,[21]1.8280,[22]1.7908,[23]1.7666,[24]1.7334,[25]1.6960,[26]1.7758,[27]1.8796,[28]1.9481,[29]1.9374,[30]1.9318,[31]1.9102,[32]1.9165,[33]1.9241,[34]1.9202,[35]1.9105,[36]1.8997,[37]1.8990,[38]1.8988,[39]1.8902,[40]1.8705,[41]1.8601,[42]1.8520,[43]1.8450,[44]1.8431,[45]1.8379,[46]1.8238,[47]1.8135,[48]1.8079,[49]1.7970,[50]1.7899,[51]1.8048,[52]1.8194,[53]1.8157,[54]1.8317,[55]1.8392,[56]1.8462,[57]1.8387,[58]1.8770,[59]1.9079,[60]1.9384,[61]1.9818,[62]2.0230,[63]2.0639,[64]2.0951,[65]2.1464,[66]2.1724,[67]2.1970,[68]2.2421,[69]2.2794,[70]2.3037,[71]2.3338,[72]2.3471,[73]2.3667,[74]2.3979,[75]2.4205,[76]2.4344,[77]2.4508,[78]2.4556,[79]2.4568,[80]2.4709,[81]2.4916,[82]2.5326,[83]2.5544,[84]2.5572,[85]2.5718,[86]2.5686,[87]2.6150,[88]2.6389,[89]2.6629,[90]2.6896,[91]2.6955,[92]2.7253,[93]2.7306,[94]2.7373,[95]2.7432,[96]2.7515,[97]2.7468,[98]2.7752,[99]2.7604,[100]2.7969,[101]2.8192,[102]2.8066,[103]2.8364,[104]2.8816,[105]2.9126,[106]2.9475,[107]2.9801,[108]3.0095,[109]3.0365,[110]3.0225,[111]3.0394,[112]3.0510,[113]3.0647,[114]3.0633,[115]3.0955,[116]3.1321,[117]3.1530,[118]3.1444,[119]3.1183,[120]3.1044,[121]3.1222,[122]3.1225,[123]3.1011,[124]3.0899,[125]3.0860,[126]3.0881,[127]3.0945,[128]3.0987,[129]3.1004,[130]3.1187,[131]3.1519,[132]3.1880,[133]3.1787,[134]3.1546,[135]3.1304,[136]3.1065,[137]3.0834,[138]3.0855,[139]3.1084,[140]3.1358,[141]3.1701,[142]3.1639,[143]3.1773,[144]3.1977,[145]3.2196,[146]3.2337,[147]3.2543,[148]3.2778,[149]3.2984,[150]3.3189,[151]3.3173,[152]3.3205,[153]3.3204,[154]3.3486,[155]3.3600,[156]3.3686,[157]3.3838,[158]3.3973,[159]3.3986,[160]3.4015,[161]3.4134,[162]3.4234,[163]3.4285,[164]3.4441,[165]3.4465,[166]3.4500,[167]3.4577,[168]3.4639,[169]3.4692,[170]3.4631,[171]3.4820,[172]3.4904,[173]3.4961,[174]3.5068,[175]3.5195,[176]3.5183,[177]3.5239,[178]3.5312,[179]3.5459,[180]3.5585,[181]3.5702,[182]3.5636,[183]3.5580,[184]3.5527,[185]3.5465,[186]3.5402,[187]3.5339,[188]3.5281,[189]3.5360,[190]3.5486,[191]3.5785,[192]3.6028,[193]3.6271,[194]3.6605,[195]3.6864,[196]3.7029,[197]3.7215,[198]3.7335,[199]3.7365,[200]3.7246,[201]3.7031,[202]3.6808,[203]3.7008,[204]3.7110,[205]3.7178,[206]3.7338,[207]3.7545,[208]3.7689,[209]3.7838,[210]3.8053,[211]3.8128,[212]3.8126,[213]3.7927,[214]3.7703,[215]3.7500,[216]3.7300,[217]3.7092,[218]3.6891,[219]3.6725,[220]3.6671,[221]3.6642,[222]3.6455,[223]3.6356,[224]3.6386,[225]3.6407,[226]3.6636,[227]3.6835,[228]3.6953,[229]3.7155,[230]3.7078,[231]3.7302,[232]3.7515,[233]3.7602,[234]3.7769,[235]3.7876,[236]3.8109,[237]3.8332,[238]3.8353,[239]3.8449,[240]3.8575,[241]3.8693,[242]3.8917,[243]3.9097,[244]3.9224,[245]3.9313,[246]3.9261,[247]3.9565,[248]3.9660,[249]3.9870,[250]3.9968,
llama_print_timings:        load time = 1161211.32 ms
llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)
llama_print_timings: prompt eval time =  544986.65 ms / 128000 tokens (    4.26 ms per token,   234.87 tokens per second)
llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)
llama_print_timings:       total time =  570150.91 ms / 128001 tokens

Final estimate: PPL over 250 chunks for n_ctx=512 = 3.9968 +/- 0.03538
