ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 4 CUDA devices:
  Device 0: NVIDIA RTX PRO 6000 Blackwell Workstation Edition, compute capability 12.0, VMM: yes, VRAM: 97886 MiB
  Device 1: NVIDIA RTX PRO 6000 Blackwell Workstation Edition, compute capability 12.0, VMM: yes, VRAM: 97886 MiB
  Device 2: NVIDIA RTX PRO 6000 Blackwell Workstation Edition, compute capability 12.0, VMM: yes, VRAM: 97886 MiB
  Device 3: NVIDIA GeForce RTX 5090, compute capability 12.0, VMM: yes, VRAM: 32606 MiB
main: build = 1 (04c80e3)
main: built with MSVC 19.44.35222.0 for 
main: seed  = 1337
CUDA0: using device CUDA0 - 95287 MiB free
CUDA1: using device CUDA1 - 95287 MiB free
CUDA2: using device CUDA2 - 95287 MiB free
CUDA3: using device CUDA3 - 30930 MiB free
llama_model_loader: max stdio successfully set to 2048
llama_model_loader: additional 1096 GGUFs metadata loaded.
llama_model_loader: loaded meta data with 49 key-value pairs and 1096 tensors from ./Kimi-K2-Thinking-THIREUS-BF16-SPECIAL_TENSOR-00001-of-01097.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = deepseek2
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                         general.size_label str              = 384x14B
llama_model_loader: - kv   3:                            general.license str              = other
llama_model_loader: - kv   4:                       general.license.name str              = modified-mit
llama_model_loader: - kv   5:                      deepseek2.block_count u32              = 61
llama_model_loader: - kv   6:                   deepseek2.context_length u32              = 262144
llama_model_loader: - kv   7:                 deepseek2.embedding_length u32              = 7168
llama_model_loader: - kv   8:              deepseek2.feed_forward_length u32              = 18432
llama_model_loader: - kv   9:             deepseek2.attention.head_count u32              = 64
llama_model_loader: - kv  10:          deepseek2.attention.head_count_kv u32              = 1
llama_model_loader: - kv  11:                   deepseek2.rope.freq_base f32              = 50000.000000
llama_model_loader: - kv  12: deepseek2.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  13:                deepseek2.expert_used_count u32              = 8
llama_model_loader: - kv  14:               deepseek2.expert_group_count u32              = 1
llama_model_loader: - kv  15:          deepseek2.expert_group_used_count u32              = 1
llama_model_loader: - kv  16:               deepseek2.expert_gating_func u32              = 2
llama_model_loader: - kv  17:                          general.file_type u32              = 32
llama_model_loader: - kv  18:        deepseek2.leading_dense_block_count u32              = 1
llama_model_loader: - kv  19:                       deepseek2.vocab_size u32              = 163840
llama_model_loader: - kv  20:            deepseek2.attention.q_lora_rank u32              = 1536
llama_model_loader: - kv  21:           deepseek2.attention.kv_lora_rank u32              = 512
llama_model_loader: - kv  22:             deepseek2.attention.key_length u32              = 576
llama_model_loader: - kv  23:           deepseek2.attention.value_length u32              = 512
llama_model_loader: - kv  24:         deepseek2.attention.key_length_mla u32              = 192
llama_model_loader: - kv  25:       deepseek2.attention.value_length_mla u32              = 128
llama_model_loader: - kv  26:       deepseek2.expert_feed_forward_length u32              = 2048
llama_model_loader: - kv  27:                     deepseek2.expert_count u32              = 384
llama_model_loader: - kv  28:              deepseek2.expert_shared_count u32              = 1
llama_model_loader: - kv  29:             deepseek2.expert_weights_scale f32              = 2.827000
llama_model_loader: - kv  30:              deepseek2.expert_weights_norm bool             = true
llama_model_loader: - kv  31:             deepseek2.rope.dimension_count u32              = 64
llama_model_loader: - kv  32:                deepseek2.rope.scaling.type str              = yarn
llama_model_loader: - kv  33:              deepseek2.rope.scaling.factor f32              = 64.000000
llama_model_loader: - kv  34: deepseek2.rope.scaling.original_context_length u32              = 4096
llama_model_loader: - kv  35: deepseek2.rope.scaling.yarn_log_multiplier f32              = 0.100000
llama_model_loader: - kv  36:               general.quantization_version u32              = 2
llama_model_loader: - kv  37:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  38:                         tokenizer.ggml.pre str              = kimi-k2
llama_model_loader: - kv  39:                      tokenizer.ggml.tokens arr[str,163840]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  40:                  tokenizer.ggml.token_type arr[i32,163840]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  41:                      tokenizer.ggml.merges arr[str,163328]  = ["Ġ Ġ", "ĠĠ ĠĠ", "Ġ t", "i n",...
llama_model_loader: - kv  42:                tokenizer.ggml.bos_token_id u32              = 163584
llama_model_loader: - kv  43:                tokenizer.ggml.eos_token_id u32              = 163586
llama_model_loader: - kv  44:            tokenizer.ggml.padding_token_id u32              = 163839
llama_model_loader: - kv  45:                    tokenizer.chat_template str              = {%- macro render_content(msg) -%}\n   ...
llama_model_loader: - kv  46:                                   split.no u16              = 0
llama_model_loader: - kv  47:                                split.count u16              = 1097
llama_model_loader: - kv  48:                        split.tensors.count i32              = 1096
llama_model_loader: - type  f32:  365 tensors
llama_model_loader: - type q4_0:  670 tensors
llama_model_loader: - type iq4_nl:   61 tensors
load: printing all EOG tokens:
load:   - 163586 ('<|im_end|>')
load: special tokens cache size = 256
load: token to piece cache size = 1.0606 MB
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = deepseek2
llm_load_print_meta: n_ctx_train      = 262144
llm_load_print_meta: n_embd           = 7168
llm_load_print_meta: n_layer          = 61
llm_load_print_meta: n_head           = 64
llm_load_print_meta: n_head_kv        = 64
llm_load_print_meta: n_rot            = 64
llm_load_print_meta: n_swa            = 0
llm_load_print_meta: n_swa_pattern    = 1
llm_load_print_meta: n_embd_head_k    = 192
llm_load_print_meta: n_embd_head_v    = 128
llm_load_print_meta: n_gqa            = 1
llm_load_print_meta: n_embd_k_gqa     = 12288
llm_load_print_meta: n_embd_v_gqa     = 8192
llm_load_print_meta: f_norm_eps       = 0.0e+00
llm_load_print_meta: f_norm_rms_eps   = 1.0e-05
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: f_logit_scale    = 0.0e+00
llm_load_print_meta: n_ff             = 18432
llm_load_print_meta: n_expert         = 384
llm_load_print_meta: n_expert_used    = 8
llm_load_print_meta: causal attn      = 1
llm_load_print_meta: pooling type     = 0
llm_load_print_meta: rope type        = 0
llm_load_print_meta: rope scaling     = yarn
llm_load_print_meta: freq_base_train  = 50000.0
llm_load_print_meta: freq_scale_train = 0.015625
llm_load_print_meta: n_ctx_orig_yarn  = 4096
llm_load_print_meta: rope_finetuned   = unknown
llm_load_print_meta: ssm_d_conv       = 0
llm_load_print_meta: ssm_d_inner      = 0
llm_load_print_meta: ssm_d_state      = 0
llm_load_print_meta: ssm_dt_rank      = 0
llm_load_print_meta: model type       = 671B
llm_load_print_meta: model ftype      = BF16
llm_load_print_meta: model params     = 1.026 T
llm_load_print_meta: model size       = 538.235 GiB (4.504 BPW) 
llm_load_print_meta: repeating layers = 537.005 GiB (4.504 BPW, 1024.059 B parameters)
llm_load_print_meta: general.name     = n/a
llm_load_print_meta: n_layer_dense_lead   = 1
llm_load_print_meta: n_lora_q             = 1536
llm_load_print_meta: n_lora_kv            = 512
llm_load_print_meta: n_ff_exp             = 2048
llm_load_print_meta: n_expert_shared      = 1
llm_load_print_meta: expert_weights_scale = 2.8
llm_load_print_meta: expert_weights_norm  = 1
llm_load_print_meta: expert_gating_func   = sigmoid
llm_load_print_meta: rope_yarn_log_mul    = 0.1000
print_info: vocab type       = BPE
print_info: n_vocab          = 163840
print_info: n_merges         = 163328
print_info: BOS token        = 163584 '[BOS]'
print_info: EOS token        = 163586 '<|im_end|>'
print_info: EOT token        = 163586 '<|im_end|>'
print_info: PAD token        = 163839 '[PAD]'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 163586 '<|im_end|>'
print_info: max token length = 512
llm_load_tensors: ggml ctx size =   13.37 MiB
Tensor blk.0.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.0.ffn_gate.weight buffer type overriden to CUDA0
Tensor blk.0.ffn_down.weight buffer type overriden to CUDA0
Tensor blk.0.ffn_up.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.1.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.2.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.3.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.4.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.5.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.6.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.7.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.8.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.9.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_norm.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_gate_inp.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_gate_exps.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_down_exps.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_up_exps.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_gate_shexp.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_down_shexp.weight buffer type overriden to CUDA0
Tensor blk.10.ffn_up_shexp.weight buffer type overriden to CUDA0
Tensor blk.11.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.11.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.11.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.11.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.11.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.11.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.11.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.11.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.12.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.12.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.12.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.12.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.12.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.12.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.12.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.12.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.13.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.13.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.13.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.13.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.13.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.13.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.13.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.13.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.14.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.15.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.16.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.17.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.18.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.19.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_norm.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_gate_inp.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_gate_exps.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_down_exps.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_up_exps.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_gate_shexp.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_down_shexp.weight buffer type overriden to CUDA1
Tensor blk.20.ffn_up_shexp.weight buffer type overriden to CUDA1
Tensor blk.21.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.21.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.21.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.21.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.21.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.21.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.21.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.21.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.22.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.22.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.22.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.22.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.22.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.22.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.22.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.22.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.23.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.23.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.23.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.23.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.23.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.23.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.23.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.23.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.24.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.24.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.24.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.24.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.24.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.24.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.24.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.24.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.25.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.25.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.25.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.25.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.25.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.25.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.25.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.25.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.26.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.26.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.26.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.26.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.26.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.26.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.26.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.26.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.27.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.27.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.27.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.27.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.27.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.27.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.27.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.27.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.28.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.29.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_norm.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_gate_inp.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_gate_exps.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_down_exps.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_up_exps.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_gate_shexp.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_down_shexp.weight buffer type overriden to CUDA2
Tensor blk.30.ffn_up_shexp.weight buffer type overriden to CUDA2
Tensor blk.31.ffn_norm.weight buffer type overriden to CUDA3
Tensor blk.31.ffn_gate_inp.weight buffer type overriden to CUDA3
Tensor blk.31.ffn_gate_exps.weight buffer type overriden to CUDA3
Tensor blk.31.ffn_down_exps.weight buffer type overriden to CUDA3
Tensor blk.31.ffn_up_exps.weight buffer type overriden to CUDA3
Tensor blk.31.ffn_gate_shexp.weight buffer type overriden to CUDA3
Tensor blk.31.ffn_down_shexp.weight buffer type overriden to CUDA3
Tensor blk.31.ffn_up_shexp.weight buffer type overriden to CUDA3
Tensor blk.32.ffn_norm.weight buffer type overriden to CUDA3
Tensor blk.32.ffn_gate_inp.weight buffer type overriden to CUDA3
Tensor blk.32.ffn_gate_exps.weight buffer type overriden to CUDA3
Tensor blk.32.ffn_down_exps.weight buffer type overriden to CUDA3
Tensor blk.32.ffn_up_exps.weight buffer type overriden to CUDA3
Tensor blk.32.ffn_gate_shexp.weight buffer type overriden to CUDA3
Tensor blk.32.ffn_down_shexp.weight buffer type overriden to CUDA3
Tensor blk.32.ffn_up_shexp.weight buffer type overriden to CUDA3
Tensor blk.33.ffn_norm.weight buffer type overriden to CUDA3
Tensor blk.33.ffn_gate_inp.weight buffer type overriden to CUDA3
Tensor blk.33.ffn_gate_exps.weight buffer type overriden to CUDA3
Tensor blk.33.ffn_down_exps.weight buffer type overriden to CUDA3
Tensor blk.33.ffn_up_exps.weight buffer type overriden to CUDA3
Tensor blk.33.ffn_gate_shexp.weight buffer type overriden to CUDA3
Tensor blk.33.ffn_down_shexp.weight buffer type overriden to CUDA3
Tensor blk.33.ffn_up_shexp.weight buffer type overriden to CUDA3
Tensor blk.34.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.34.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.34.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.35.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.35.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.35.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.36.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.36.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.36.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.37.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.37.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.37.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.38.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.38.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.38.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.39.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.39.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.39.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.40.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.40.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.40.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.41.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.41.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.41.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.42.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.42.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.42.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.43.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.43.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.43.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.44.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.44.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.44.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.45.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.45.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.45.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.46.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.46.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.46.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.47.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.47.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.47.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.48.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.48.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.48.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.49.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.49.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.49.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.50.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.50.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.50.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.51.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.51.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.51.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.52.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.52.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.52.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.53.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.53.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.53.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.54.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.54.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.54.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.55.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.55.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.55.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.56.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.56.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.56.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.57.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.57.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.57.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.58.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.58.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.58.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.59.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.59.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.59.ffn_up_exps.weight buffer type overriden to CPU
Tensor blk.60.ffn_gate_exps.weight buffer type overriden to CPU
Tensor blk.60.ffn_down_exps.weight buffer type overriden to CPU
Tensor blk.60.ffn_up_exps.weight buffer type overriden to CPU
llm_load_tensors: offloading 61 repeating layers to GPU
llm_load_tensors: offloading non-repeating layers to GPU
llm_load_tensors: offloaded 62/62 layers to GPU
llm_load_tensors:        CPU buffer size = 244944.00 MiB
llm_load_tensors:  CUDA_Host buffer size =   630.00 MiB
llm_load_tensors:      CUDA0 buffer size = 92305.55 MiB
llm_load_tensors:      CUDA1 buffer size = 92229.51 MiB
llm_load_tensors:      CUDA2 buffer size = 92653.36 MiB
llm_load_tensors:      CUDA3 buffer size = 28390.66 MiB
....................................................................................................
============ llm_prepare_mla: need to compute 61 wkv_b tensors
================= Adjusted mainline llama.cpp MLA tensors to ik_llama.cpp
Computed blk.0.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.1.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.2.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.3.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.4.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.5.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.6.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.7.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.8.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.9.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.10.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.11.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.12.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.13.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.14.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.15.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.16.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.17.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.18.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA0
Computed blk.19.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.20.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.21.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.22.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.23.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.24.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.25.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.26.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.27.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.28.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.29.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.30.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.31.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.32.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.33.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.34.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.35.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.36.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.37.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA1
Computed blk.38.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.39.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.40.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.41.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.42.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.43.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.44.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.45.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.46.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.47.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.48.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.49.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.50.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.51.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.52.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.53.attn_kv_b.weight as 512 x 16384 and storellama_new_context_with_model: n_ctx         = 512
llama_new_context_with_model: n_batch       = 512
llama_new_context_with_model: n_ubatch      = 512
llama_new_context_with_model: flash_attn    = 1
llama_new_context_with_model: mla_attn      = 3
llama_new_context_with_model: attn_max_b    = 512
llama_new_context_with_model: fused_moe     = 1
llama_new_context_with_model: grouped er    = 0
llama_new_context_with_model: fused_up_gate = 1
llama_new_context_with_model: fused_mmad    = 1
llama_new_context_with_model: rope_cache    = 0
llama_new_context_with_model: graph_reuse   = 0
llama_new_context_with_model: k_cache_hadam = 0
llama_new_context_with_model: split_mode_graph_scheduling = 0
llama_new_context_with_model: ser           = -1, 0
llama_new_context_with_model: freq_base     = 50000.0
llama_new_context_with_model: freq_scale    = 0.015625
llama_kv_cache_init:      CUDA0 KV buffer size =    10.69 MiB
llama_kv_cache_init:      CUDA1 KV buffer size =    10.69 MiB
llama_kv_cache_init:      CUDA2 KV buffer size =    10.12 MiB
llama_kv_cache_init:      CUDA3 KV buffer size =     2.81 MiB
llama_new_context_with_model: KV self size  =   34.31 MiB, c^KV (f16):   34.31 MiB, kv^T: not used
llama_new_context_with_model:  CUDA_Host  output buffer size =     0.62 MiB
llama_new_context_with_model:      CUDA0 compute buffer size =   174.75 MiB
llama_new_context_with_model:      CUDA1 compute buffer size =   201.27 MiB
llama_new_context_with_model:      CUDA2 compute buffer size =   208.63 MiB
llama_new_context_with_model:      CUDA3 compute buffer size =   334.00 MiB
llama_new_context_with_model:  CUDA_Host compute buffer size =   159.25 MiB
llama_new_context_with_model: graph nodes  = 3282
llama_new_context_with_model: graph splits = 141
XXXXXXXXXXXXXXXXXXXXX Setting only active experts offload

system_info: n_threads = 36 / 36 | AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | 
perplexity: saving all logits to bench_kld_result.baseline.q4_0.250.bin
perplexity: tokenizing the input ..
perplexity: tokenization took 1377.13 ms
perplexity: calculating perplexity over 250 chunks, n_ctx=512, batch_size=512, n_seq=1
perplexity: 45.60 seconds per pass - ETA 3 hours 10.02 minutes
d in buffer CUDA2
Computed blk.54.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.55.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA2
Computed blk.56.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA3
Computed blk.57.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA3
Computed blk.58.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA3
Computed blk.59.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA3
Computed blk.60.attn_kv_b.weight as 512 x 16384 and stored in buffer CUDA3
[1]75.0183,[2]13.5405,[3]6.6887,[4]4.1677,[5]3.2339,[6]2.6970,[7]2.3571,[8]2.1412,[9]2.0859,[10]2.0307,[11]2.0445,[12]2.2529,[13]2.3342,[14]2.3129,[15]2.1883,[16]2.0924,[17]2.0066,[18]1.9472,[19]1.8827,[20]1.8343,[21]1.7837,[22]1.7492,[23]1.7152,[24]1.6802,[25]1.6460,[26]1.7195,[27]1.8180,[28]1.8830,[29]1.8722,[30]1.8637,[31]1.8403,[32]1.8363,[33]1.8368,[34]1.8237,[35]1.8084,[36]1.7959,[37]1.7937,[38]1.7928,[39]1.7755,[40]1.7523,[41]1.7360,[42]1.7201,[43]1.7036,[44]1.6929,[45]1.6889,[46]1.6779,[47]1.6697,[48]1.6661,[49]1.6572,[50]1.6506,[51]1.6640,[52]1.6784,[53]1.6764,[54]1.6941,[55]1.7039,[56]1.7129,[57]1.7053,[58]1.7431,[59]1.7723,[60]1.7987,[61]1.8367,[62]1.8743,[63]1.9115,[64]1.9420,[65]1.9904,[66]2.0158,[67]2.0398,[68]2.0783,[69]2.1120,[70]2.1353,[71]2.1636,[72]2.1771,[73]2.1955,[74]2.2243,[75]2.2466,[76]2.2606,[77]2.2753,[78]2.2808,[79]2.2825,[80]2.2932,[81]2.3120,[82]2.3503,[83]2.3707,[84]2.3737,[85]2.3875,[86]2.3865,[87]2.4252,[88]2.4458,[89]2.4687,[90]2.4919,[91]2.4959,[92]2.5236,[93]2.5301,[94]2.5374,[95]2.5425,[96]2.5513,[97]2.5482,[98]2.5739,[99]2.5569,[100]2.5909,[101]2.6116,[102]2.6015,[103]2.6311,[104]2.6746,[105]2.7037,[106]2.7353,[107]2.7668,[108]2.7960,[109]2.8220,[110]2.8092,[111]2.8241,[112]2.8359,[113]2.8434,[114]2.8427,[115]2.8740,[116]2.9072,[117]2.9256,[118]2.9174,[119]2.8937,[120]2.8792,[121]2.8967,[122]2.8970,[123]2.8760,[124]2.8665,[125]2.8655,[126]2.8696,[127]2.8758,[128]2.8797,[129]2.8827,[130]2.9000,[131]2.9317,[132]2.9668,[133]2.9576,[134]2.9343,[135]2.9112,[136]2.8887,[137]2.8671,[138]2.8709,[139]2.8922,[140]2.9174,[141]2.9492,[142]2.9442,[143]2.9567,[144]2.9757,[145]2.9954,[146]3.0057,[147]3.0260,[148]3.0478,[149]3.0673,[150]3.0866,[151]3.0848,[152]3.0882,[153]3.0881,[154]3.1138,[155]3.1250,[156]3.1337,[157]3.1473,[158]3.1591,[159]3.1613,[160]3.1648,[161]3.1758,[162]3.1851,[163]3.1910,[164]3.2050,[165]3.2074,[166]3.2112,[167]3.2180,[168]3.2245,[169]3.2297,[170]3.2241,[171]3.2412,[172]3.2484,[173]3.2534,[174]3.2636,[175]3.2752,[176]3.2740,[177]3.2798,[178]3.2857,[179]3.3005,[180]3.3133,[181]3.3240,[182]3.3191,[183]3.3151,[184]3.3110,[185]3.3060,[186]3.3012,[187]3.2955,[188]3.2910,[189]3.2982,[190]3.3109,[191]3.3396,[192]3.3610,[193]3.3825,[194]3.4130,[195]3.4378,[196]3.4538,[197]3.4709,[198]3.4804,[199]3.4840,[200]3.4710,[201]3.4505,[202]3.4299,[203]3.4495,[204]3.4587,[205]3.4655,[206]3.4803,[207]3.5003,[208]3.5140,[209]3.5276,[210]3.5481,[211]3.5549,[212]3.5548,[213]3.5340,[214]3.5133,[215]3.4934,[216]3.4735,[217]3.4542,[218]3.4350,[219]3.4181,[220]3.4099,[221]3.4068,[222]3.3901,[223]3.3789,[224]3.3802,[225]3.3820,[226]3.4023,[227]3.4207,[228]3.4310,[229]3.4498,[230]3.4410,[231]3.4618,[232]3.4821,[233]3.4894,[234]3.5050,[235]3.5117,[236]3.5332,[237]3.5538,[238]3.5530,[239]3.5619,[240]3.5739,[241]3.5851,[242]3.6061,[243]3.6222,[244]3.6352,[245]3.6443,[246]3.6365,[247]3.6641,[248]3.6732,[249]3.6919,[250]3.6998,
llama_print_timings:        load time = 3618463.61 ms
llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)
llama_print_timings: prompt eval time = 4546967.08 ms / 128000 tokens (   35.52 ms per token,    28.15 tokens per second)
llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)
llama_print_timings:       total time = 4572572.04 ms / 128001 tokens

Final estimate: PPL over 250 chunks for n_ctx=512 = 3.6998 +/- 0.03219
