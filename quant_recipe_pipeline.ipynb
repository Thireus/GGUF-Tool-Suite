{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Recipe Pipeline\n",
                "Configure your ‚öôÔ∏è Pipeline Parameters, then run all cells ‚ñ∂Ô∏è\n",
                "\n",
                "> üîß **Adjust parameters** such as `--cpu-tensors-max-size` or `--gpu-quants` as needed for your specific hardware.\n",
                "\n",
                "> ‚ö†Ô∏è q\\*_K and q\\*_KV quants must be used with a capital \"K\" and \"KV\" letters at the end of their name. All other quants are lowercase.\n",
                "\n",
                "- List of quants compatible with `ik_llama.cpp`:\n",
                "\n",
                "> iq1_bn iq1_kt iq1_m iq1_s iq1_s_r4 iq2_bn iq2_bn_r4 iq2_k iq2_k_r4 iq2_kl iq2_ks iq2_kt iq2_m iq2_m_r4 iq2_s iq2_xs iq2_xs_r4 iq2_xxs iq2_xxs_r4 iq3_k iq3_k_r4 iq3_kl iq3_ks iq3_kt iq3_m iq3_s iq3_s_r4 iq3_xs iq3_xxs iq3_xxs_r4 iq4_k iq4_k_r4 iq4_ks iq4_ks_r4 iq4_kss iq4_kt iq4_nl iq4_nl_r4 iq4_xs iq4_xs_r8 iq5_k iq5_k_r4 iq5_ks iq5_ks_r4 iq6_k q1_m_r4 q2_K q2_k_r4 q2_k_s q3_K q3_k_l q3_k_m q3_k_r4 q3_k_s q4_0 q4_0_4_4 q4_0_4_8 q4_0_8_8 q4_0_r8 q4_1 q4_K q4_k_m q4_k_r4 q4_k_s q5_0 q5_0_r4 q5_1 q5_K q5_k_m q5_k_r4 q5_k_s q6_0 q6_0_r4 q6_K q6_k_r4 q8_0 q8_0_r8 q8_k_r8 q8_KV q8_kv_r8\n",
                "\n",
                "- List of [quants compatible](https://github.com/ggml-org/llama.cpp/blob/master/tools/quantize/README.md) with `llama.cpp`:\n",
                "\n",
                "> iq1_m iq1_s iq2_m iq2_s iq2_xs iq2_xxs iq3_m iq3_s iq3_xs iq3_xxs iq4_nl iq4_xs mxfp4_moe tq1_0 tq2_0 q2_K q2_k_s q3_K q3_k_l q3_k_m q3_k_s q4_0 q4_1 q4_K q4_k_m q4_k_s q5_0 q5_1 q5_K q5_k_m q5_k_s q6_K q8_0\n",
                "\n",
                "See https://huggingface.co/Thireus/collections for the complete list of supported models and available quants - NOT ALL QUANTS ARE AVAILABLE! PLEASE CHECK FIRST!\n",
                "\n",
                "Need help choosing your quants? See how quants perform on different hardware here: https://github.com/Thireus/GGUF-Tool-Suite/tree/main/quants_graphs\n",
                "\n",
                "> Recipe files can also be turned back into Google Colab pipeline parameters - [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Thireus/GGUF-Tool-Suite/blob/main/recipe_to_colab_params.ipynb) or locally with `recipe_to_colab_params.py`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "98aa646d",
            "metadata": {
                "id": "params"
            },
            "outputs": [],
            "source": [
                "# @title ‚öôÔ∏è Pipeline Parameters\n",
                "repo_url = \"https://github.com/Thireus/GGUF-Tool-Suite.git\"         #@param {type:\"string\"}\n",
                "model_name = \"DeepSeek-R1-0528\"                                     #@param {type:\"string\"}\n",
                "model_link = \"https://huggingface.co/deepseek-ai/DeepSeek-R1-0528\"  #@param {type:\"string\"}\n",
                "\n",
                "# regex lists as Python lists of strings - CPU/GPU-friendly tensor names can be found in *.recipe file of the model directory\n",
                "cpu_tensors = [r\"^blk\\.([3-9]|[1-5][0-9]|60)\\.ffn_down_exps\\.weight$\", r\"^blk\\.([3-9]|[1-5][0-9]|60)\\.ffn_up_exps\\.weight$\", r\"^blk\\.([3-9]|[1-5][0-9]|60)\\.ffn_gate_exps\\.weight$\"]   #@param {type:\"raw\"}\n",
                "gpu_tensors = [r\".*\"]    #@param {type:\"raw\"}\n",
                "\n",
                "# quant types for cpu-friendly and gpu-friendly tensor assignments\n",
                "cpu_quants = [\"iq4_ks\", \"iq3_k\", \"iq2_ks\", \"iq1_m_r4\"]   #@param {type:\"raw\"}\n",
                "gpu_quants = [\"q8_0\", \"iq5_k_r4\", \"iq6_k\"]              #@param {type:\"raw\"}\n",
                "\n",
                "# sizes & tuning\n",
                "cpu_tensors_max_size = \"230\"    #@param {type:\"string\"}\n",
                "gpu_tensors_max_size = \"95%\"    #@param {type:\"string\"}\n",
                "tolerance = 0.01                #@param {type:\"number\"}\n",
                "exponential_factor = 8          #@param {type:\"integer\"}\n",
                "\n",
                "# assignment override\n",
                "cpu_assign_qtype = \"\"        #@param {type:\"string\"}\n",
                "cpu_assign_tensors = []        #@param {type:\"raw\"}\n",
                "gpu_assign_qtype = \"iq4_xs\"    #@param {type:\"string\"}\n",
                "gpu_assign_tensors = [r\"^blk\\.([0-9]|[1-5][0-9]|60)\\.attn_k_b\\.weight$=q8_0\"] #@param {type:\"raw\"}\n",
                "\n",
                "# harmonization options (optional)\n",
                "# harmonize_tensors: list-of-lists of regex strings; each inner list declares a group whose matching tensors (within a class) will be qtype harmonized layer-wise.\n",
                "# Default harmonizes ffn_up_exps and ffn_gate_exps fused pairs used by ik_llama.cpp (speed boost ~15%).\n",
                "harmonize_tensors = [[r\"^blk\\..*\\.ffn_up_exps.*\", r\"^blk\\..*\\.ffn_gate_exps.*\"]]   #@param {type:\"raw\"}\n",
                "# harmonization_technique: 0=disabled, 1=max, 2=mean, 3=min (default)\n",
                "harmonization_technique = 3    #@param {type:\"integer\"}\n",
                "\n",
                "# calibration data filename (\"kld_results.csv\" or \"kld_results_partial.csv\" or \"ppl_results.csv\" or \"ppl_results_partial.csv\" are automatically used by default in this order when empty)\n",
                "csv_filename = \"\" #@param {type:\"string\"}\n",
                "\n",
                "# calibration data qtype (leave empty for auto-selection which will choose the lowest bpw) - list of available qtypes can be found in the calibration data file\n",
                "qtype = \"\"                  #@param {type:\"string\"}\n",
                "\n",
                "# Use the greedy priority-queue quant assignment instead of the default method.\n",
                "use_greedy_quant_assign = False  #@param {type:\"boolean\"}\n",
                "# Optional path to CSV with quant degradation values (only valid when use_greedy_quant_assign=True).\n",
                "quant_degradation_csv = \"\"     #@param {type:\"string\"}\n",
                "# Optional equation to compute degradation from bpw. Only valid when use_greedy_quant_assign=True.\n",
                "quant_degradation_equation = \"\" #@param {type:\"string\"}\n",
                "# Synergistic tensors for greedy quant assignment: list-of-lists of regex patterns. Each inner list defines tensors whose losses should be adjusted together. Use \"\" to disable.\n",
                "synergistic_tensors = [[r\"blk\\..*\\.ffn_up_exps.*\", r\"blk\\..*\\.ffn_gate_exps.*\", r\"blk\\..*\\.ffn_down_exps.*\"]]  #@param {type:\"raw\"}\n",
                "# Strength of synergy-based loss adjustment (0 = disabled, 1 = fully averaged losses). Only valid when synergistic_tensors is set.\n",
                "synergy_strength = 0.0          #@param {type:\"number\"}\n",
                "\n",
                "# additional flags (advanced and optional)\n",
                "debug = False               #@param {type:\"boolean\"}\n",
                "info = False                #@param {type:\"boolean\"}\n",
                "ignore_f32 = False          #@param {type:\"boolean\"}\n",
                "no_fallback = False         #@param {type:\"boolean\"}\n",
                "tensors_from_csv = False    #@param {type:\"boolean\"}\n",
                "cpu_irq_k = 1.5             #@param {type:\"number\"}\n",
                "gpu_irq_k = 1.5             #@param {type:\"number\"}\n",
                "skip_gpg = False            #@param {type:\"boolean\"}\n",
                "\n",
                "# other pipeline parameters (optional)\n",
                "display_graphs = True       #@param {type:\"boolean\"}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3a1e3dd5",
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd ~\n",
                "!rm -rf GGUF-Tool-Suite # Clear all the things"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2568d92f",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash -e -s \"$repo_url\" \"$model_name\" \"$csv_filename\"\n",
                "REPO_URL=\"$1\"\n",
                "MODEL_NAME=\"$2\"\n",
                "CSV_FILENAME=\"$3\"\n",
                "\n",
                "# 1) Clone (if needed) and cd into repo\n",
                "if [ ! -d GGUF-Tool-Suite ]; then\n",
                "  echo \"‚Ü≥ GGUF-Tool-Suite not found; cloning from $REPO_URL...\"\n",
                "  GIT_LFS_SKIP_SMUDGE=1 git clone \"$REPO_URL\" \\\n",
                "    || { echo \"‚ùå ERROR: failed to clone GGUF-Tool-Suite. Aborting.\"; exit 1; }\n",
                "fi\n",
                "cd GGUF-Tool-Suite\n",
                "\n",
                "# 2) Verify model directory exists\n",
                "if [ ! -d models/$MODEL_NAME ]; then\n",
                "  echo \"‚ùå ERROR: models/$MODEL_NAME not found; this model is not supported yet.\"\n",
                "  exit 1\n",
                "fi\n",
                "\n",
                "# 3) Link download.conf (or abort if missing)\n",
                "if [ -f models/$MODEL_NAME/download.conf ]; then\n",
                "  ln -sf models/$MODEL_NAME/download.conf .\n",
                "else\n",
                "  echo \"‚ùå ERROR: download.conf for '$MODEL_NAME' missing; this model isn't meant to be used here.\"\n",
                "  exit 1\n",
                "fi\n",
                "\n",
                "# 4) Link calibration data csv file (or abort with warning)\n",
                "rm -f *.csv\n",
                "if [ -n \"$CSV_FILENAME\" ]; then\n",
                "  # CSV filename provided\n",
                "  if [ -f \"models/$MODEL_NAME/$CSV_FILENAME\" ]; then\n",
                "    ln -sf \"models/$MODEL_NAME/$CSV_FILENAME\" custom_results.csv\n",
                "  else\n",
                "    echo \"‚ùå ERROR: File 'models/$MODEL_NAME/$CSV_FILENAME' does not exist.\"\n",
                "    # If the filename ends with \"_interpolated.csv\", try to suggest a matching \"_partial\" file.\n",
                "    if [[ \"$CSV_FILENAME\" == *_interpolated.csv ]]; then\n",
                "      base=\"${CSV_FILENAME%_partial*}\"\n",
                "      suggestion=$(find \"models/$MODEL_NAME\" -maxdepth 1 \\( -type f -o -type l \\) -name \"${base}*\" | grep -v \"_interpolated.csv\" | grep \"_partial\" | head -n 1)\n",
                "      if [ -n \"$suggestion\" ]; then\n",
                "        suggestion_name=$(basename \"$suggestion\")\n",
                "        echo \"‚ö†Ô∏è  Hint: It looks like '$CSV_FILENAME' was an auto-generated interpolated file.\"\n",
                "        echo \"    You may need to use '$suggestion_name' instead in your 'csv_filename' pipeline parameter.\"\n",
                "      else\n",
                "        echo \"‚ÑπÔ∏è  No '_partial' CSV found either.\"\n",
                "      fi\n",
                "    fi\n",
                "    exit 1\n",
                "  fi\n",
                "else\n",
                "  # CSV filename not provided\n",
                "  if [ -f \"models/$MODEL_NAME/kld_results.csv\" ]; then\n",
                "    ln -sf \"models/$MODEL_NAME/kld_results.csv\" .\n",
                "  elif [ -f \"models/$MODEL_NAME/kld_results_partial.csv\" ]; then\n",
                "    ln -sf \"models/$MODEL_NAME/kld_results_partial.csv\" .\n",
                "    echo \"‚ö†Ô∏è WARNING: partial calibrated kld_results_partial.csv found for '$MODEL_NAME'; will try to interpolate missing results as best as we can, but this will unlikely produce kld-optimum quant mixes (so please don't use for production) - full calibrated data likely coming soon.\"\n",
                "  elif [ -f \"models/$MODEL_NAME/ppl_results.csv\" ]; then\n",
                "    ln -sf \"models/$MODEL_NAME/ppl_results.csv\" .\n",
                "  elif [ -f \"models/$MODEL_NAME/ppl_results_partial.csv\" ]; then\n",
                "    ln -sf \"models/$MODEL_NAME/ppl_results_partial.csv\" .\n",
                "    echo \"‚ö†Ô∏è WARNING: partial calibrated ppl_results_partial.csv found for '$MODEL_NAME'; will try to interpolate missing results as best as we can, but this will unlikely produce ppl-optimum quant mixes (so please don't use for production) - full calibrated data likely coming soon.\"\n",
                "  else\n",
                "    echo \"‚ùå ERROR: Missing calibration data file *_results.csv; support for '$MODEL_NAME' likely coming soon.\"\n",
                "    exit 1\n",
                "  fi\n",
                "fi\n",
                "\n",
                "# 5) Make all scripts executable\n",
                "chmod +x *.sh *.py\n",
                "\n",
                "# 6) Link download.conf\n",
                "if [ -f models/$MODEL_NAME/download.conf ]; then\n",
                "  ln -sf models/$MODEL_NAME/download.conf .\n",
                "else\n",
                "  echo \"‚ùå ERROR: download.conf not found for '$MODEL_NAME'; support for '$MODEL_NAME' likely coming soon.\"\n",
                "  exit 1\n",
                "fi\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cde5856a",
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd GGUF-Tool-Suite/models/{model_name}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22fa5266",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash -e -s \"$csv_filename\"\n",
                "CSV_FILENAME=\"$1\"\n",
                "\n",
                "if [ -n \"$CSV_FILENAME\" ]; then\n",
                "  # split base and extension safely\n",
                "  case \"$CSV_FILENAME\" in\n",
                "    *.*)\n",
                "      base=\"${CSV_FILENAME%.*}\"\n",
                "      ;;\n",
                "    *)\n",
                "      base=\"$CSV_FILENAME\"\n",
                "      ;;\n",
                "  esac\n",
                "\n",
                "  if [ -f \"$CSV_FILENAME\" ] && [ \"${base##*_}\" != \"partial\" ]; then\n",
                "    # Complete CSV exists and is not a _partial file\n",
                "    echo \"Complete '$CSV_FILENAME' already exists. Skipping interpolation...\"\n",
                "    ln -sf \"$CSV_FILENAME\" \"csv_results_to_plot.csv\"\n",
                "\n",
                "  elif [ -f \"$CSV_FILENAME\" ]; then\n",
                "    # File exists but filename ends with _partial -> interpolation path\n",
                "    echo \"Interpolation of '$CSV_FILENAME' necessary.\"\n",
                "    ln -sf \"$CSV_FILENAME\" \"csv_results_to_plot.csv\"\n",
                "\n",
                "    # prepare pattern for interpolated outputs: e.g. base_*interpolated.csv\n",
                "    pattern=\"${base}\"_*interpolated.csv\n",
                "\n",
                "    # enable nullglob so the pattern expands to zero args if no match\n",
                "    shopt -s nullglob\n",
                "    # remove any old interpolated files that match the pattern\n",
                "    old_interpolated=( $pattern )\n",
                "    if [ \"${#old_interpolated[@]}\" -gt 0 ]; then\n",
                "      rm -f \"${old_interpolated[@]}\"\n",
                "    fi\n",
                "\n",
                "    # run interpolation script (adjust path as needed)\n",
                "    python ../../fill_missing_metric.py \"$CSV_FILENAME\"\n",
                "\n",
                "    # look for generated interpolated file(s)\n",
                "    new_interpolated=( $pattern )\n",
                "    if [ \"${#new_interpolated[@]}\" -gt 0 ]; then\n",
                "      # link the first matching interpolated file to csv_results_to_plot_inter.csv\n",
                "      ln -sf \"${new_interpolated[0]}\" \"csv_results_to_plot_inter.csv\"\n",
                "    else\n",
                "      echo \"‚ùå ERROR: interpolation did not produce any '${base}_*interpolated.csv' output.\"\n",
                "      shopt -u nullglob\n",
                "      exit 1\n",
                "    fi\n",
                "    # restore nullglob off\n",
                "    shopt -u nullglob\n",
                "\n",
                "  else\n",
                "    echo \"‚ùå ERROR: File '$CSV_FILENAME' not found.\"\n",
                "    exit 1\n",
                "  fi\n",
                "elif [ -f kld_results.csv ]; then \\\n",
                "    echo \"Complete pkld_results.csv already exists. Skipping interpolation...\"; \\\n",
                "    ln -sf kld_results.csv csv_results_to_plot.csv; \\\n",
                "elif [ -f kld_results_partial.csv ]; then \\\n",
                "    echo \"Interpolation of kld_results.csv necessary.\"; \\\n",
                "    ln -sf kld_results_partial.csv csv_results_to_plot.csv; \\\n",
                "    rm -f kld_results_partial_*interpolated.csv; \\\n",
                "    python ../../fill_missing_metric.py kld_results_partial.csv; \\\n",
                "    ln -sf kld_results_partial_*interpolated.csv csv_results_to_plot_inter.csv; \\\n",
                "elif [ -f ppl_results.csv ]; then \\\n",
                "    echo \"Complete ppl_results.csv already exists. Skipping interpolation...\"; \\\n",
                "    ln -sf ppl_results.csv csv_results_to_plot.csv; \\\n",
                "elif [ -f ppl_results_partial.csv ]; then \\\n",
                "    echo \"Interpolation of ppl_results.csv necessary.\"; \\\n",
                "    ln -sf ppl_results_partial.csv csv_results_to_plot.csv; \\\n",
                "    rm -f ppl_results_partial_*interpolated.csv; \\\n",
                "    python ../../fill_missing_metric.py ppl_results_partial.csv; \\\n",
                "    ln -sf ppl_results_partial_*interpolated.csv csv_results_to_plot_inter.csv; \\\n",
                "else \\\n",
                "    echo \"‚ùå Error: No calibration data file found. Aborting.\"; \\\n",
                "    exit 1; \\\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "adae401b",
            "metadata": {},
            "outputs": [],
            "source": [
                "![ \"$display_graphs\" = \"True\" ] && cp ../../plot_ppl.py plot_ppl.tmp.py && \\\n",
                "sed -Ei \\\n",
                "  -e '/^[[:space:]]*root[[:space:]]*=[[:space:]]*tk\\.Tk\\(\\)/s|.*|# &|' \\\n",
                "  -e '/^[[:space:]]*root\\./s|.*|# &|' \\\n",
                "  -e '$a plt.show()' \\\n",
                "  plot_ppl.tmp.py\n",
                "\n",
                "import os\n",
                "interp_csv = os.path.isfile(\"csv_results_to_plot_inter.csv\")\n",
                "\n",
                "if display_graphs:\n",
                "  # Utility to strip ‚Äú=‚Ä¶‚Äù from any entries\n",
                "  def strip_assign(regex):\n",
                "      return regex.split('=')[0]\n",
                "\n",
                "  # Function to run the plotting script for each regex\n",
                "  def run_for_list(name, regex_list, strip_eq=False):\n",
                "      if not regex_list:\n",
                "        return\n",
                "      print(f\"## Using `{name}`\")\n",
                "      for rx in regex_list:\n",
                "        clean_rx = strip_assign(rx) if strip_eq else rx\n",
                "        # this print can be copy‚Äë&‚Äëpasted into a new cell, or you can %run directly below\n",
                "        if interp_csv:\n",
                "          print(f\"%run plot_ppl.tmp.py csv_results_to_plot.csv --interp_csv csv_results_to_plot_inter.csv --tensors '{clean_rx}'\")\n",
                "          %run plot_ppl.tmp.py csv_results_to_plot.csv --interp_csv csv_results_to_plot_inter.csv --tensors '{clean_rx}'\n",
                "        else:\n",
                "          print(f\"%run plot_ppl.tmp.py csv_results_to_plot.csv --tensors '{clean_rx}'\")\n",
                "          %run plot_ppl.tmp.py csv_results_to_plot.csv --tensors '{clean_rx}'\n",
                "      print()\n",
                "\n",
                "  #Now invoke for each\n",
                "  run_for_list(\"gpu_assign_tensors\", gpu_assign_tensors, strip_eq=True)\n",
                "  run_for_list(\"cpu_assign_tensors\", cpu_assign_tensors, strip_eq=True)\n",
                "  run_for_list(\"gpu_tensors\", gpu_tensors)\n",
                "  run_for_list(\"cpu_tensors\", cpu_tensors)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6ebfc19b",
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install pgpy # Install dependency to validate gpg signatures"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c336d64d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, glob\n",
                "import shlex, subprocess\n",
                "import json\n",
                "\n",
                "def add_flag(cmd, key, val):\n",
                "    if isinstance(val, bool):\n",
                "        if val:\n",
                "            cmd.append(f\"--{key}\")\n",
                "    elif val is not None:\n",
                "        cmd.extend([f\"--{key}\", str(val)])\n",
                "\n",
                "def add_list_flag(cmd, key, vals):\n",
                "    if vals:\n",
                "        cmd.append(f\"--{key}\")\n",
                "        cmd.extend(vals)\n",
                "\n",
                "def add_list_of_list_flag(cmd, key, val_groups, *, allow_empty=False):\n",
                "    \"\"\"\n",
                "    Add --<key> followed by group values. By default, empty string or empty list is treated\n",
                "    as \"no flag\". If allow_empty is True, an explicit empty argument is added (['--key', '']).\n",
                "    \"\"\"\n",
                "    if val_groups is None:\n",
                "        return\n",
                "\n",
                "    # explicit empty string or empty list -> only add when allow_empty=True\n",
                "    if (isinstance(val_groups, str) and val_groups == \"\") or (\n",
                "        isinstance(val_groups, (list, tuple)) and len(val_groups) == 0\n",
                "    ):\n",
                "        if not allow_empty:\n",
                "            return\n",
                "        cmd.append(f\"--{key}\")\n",
                "        cmd.append(\"\")   # explicit empty argument\n",
                "        return\n",
                "\n",
                "    # pre-joined string (non-empty)\n",
                "    if isinstance(val_groups, str):\n",
                "        cmd.append(f\"--{key}\")\n",
                "        cmd.append(val_groups)\n",
                "        return\n",
                "\n",
                "    # iterable of groups\n",
                "    cmd.append(f\"--{key}\")\n",
                "    for grp in val_groups:\n",
                "        if isinstance(grp, (list, tuple)):\n",
                "            cmd.append(\",\".join(str(x) for x in grp))\n",
                "        elif isinstance(grp, str):\n",
                "            cmd.append(grp)\n",
                "        else:\n",
                "            raise TypeError(f\"Unsupported group type for --{key}: {type(grp)}\")\n",
                "\n",
                "# Determine which file to use\n",
                "if csv_filename and os.path.isfile(csv_filename):\n",
                "    if not csv_filename.endswith(\"_partial.csv\"):\n",
                "        input_file = csv_filename\n",
                "    else:\n",
                "        # Search for the first matching file in the current directory\n",
                "        partial_files = glob.glob(\"*_partial_*interpolated.csv\")\n",
                "        if partial_files:\n",
                "            input_file = sorted(partial_files)[0]  # Use the first one alphabetically\n",
                "        else:\n",
                "            raise FileNotFoundError(\"No suitable input file found: *_partial_*interpolated.csv\")\n",
                "elif os.path.isfile(\"kld_results.csv\"):\n",
                "    input_file = \"kld_results.csv\"\n",
                "elif os.path.isfile(\"ppl_results.csv\"):\n",
                "    input_file = \"ppl_results.csv\"\n",
                "else:\n",
                "    # Search for the first matching file in the current directory\n",
                "    partial_files = glob.glob(\"*_*interpolated.csv\")\n",
                "    if partial_files:\n",
                "        input_file = sorted(partial_files)[0]  # Use the first one alphabetically\n",
                "    else:\n",
                "        raise FileNotFoundError(\"No suitable input file found: kld_results.csv, ppl_results.csv, *_*interpolated.csv, or *_partial_*interpolated.csv\")\n",
                "\n",
                "cmd = [\"python\", \"../../quant_assign.py\", input_file]\n",
                "\n",
                "# -----------------------------------------------------------------------------\n",
                "# Mirror quant_assign.py's argument constraints but *do not* raise errors here.\n",
                "# Instead: silently only include greedy-specific parameters when --use-greedy-quant-assign is True.\n",
                "# This ensures invalid combinations are simply not passed to quant_assign.py.\n",
                "# -----------------------------------------------------------------------------\n",
                "if use_greedy_quant_assign:\n",
                "    # Add greedy mode flag and only then add greedy-related options when present\n",
                "    add_flag(cmd, \"use-greedy-quant-assign\", use_greedy_quant_assign)\n",
                "    if quant_degradation_csv:\n",
                "        add_flag(cmd, \"quant-degradation-csv\", quant_degradation_csv)\n",
                "    if quant_degradation_equation:\n",
                "        add_flag(cmd, \"quant-degradation-equation\", quant_degradation_equation)\n",
                "    # synergistic_tensors may be an explicit empty string/list to disable; honor that via allow_empty\n",
                "    if synergistic_tensors is not None:\n",
                "        add_list_of_list_flag(cmd, \"synergistic-tensors\", synergistic_tensors, allow_empty=True)\n",
                "        # Only add synergy_strength if synergistic_tensors was provided and non-empty\n",
                "        # (the helper add_list_of_list_flag treats '' / [] specially when allow_empty=True)\n",
                "        if synergy_strength and synergistic_tensors not in (None, \"\", []):\n",
                "            add_flag(cmd, \"synergy-strength\", synergy_strength)\n",
                "else:\n",
                "    # Greedy mode disabled: silently ignore greedy-only params (do not add them to cmd)\n",
                "    pass\n",
                "# -----------------------------------------------------------------------------\n",
                "add_flag(cmd, \"tolerance\", tolerance)\n",
                "add_flag(cmd, \"cpu-irq-k\", cpu_irq_k)\n",
                "add_flag(cmd, \"gpu-irq-k\", gpu_irq_k)\n",
                "if qtype:\n",
                "    add_flag(cmd, \"qtype\", qtype)\n",
                "if cpu_assign_qtype:\n",
                "    add_flag(cmd, \"cpu-assign-qtype\", cpu_assign_qtype)\n",
                "if gpu_assign_qtype:\n",
                "    add_flag(cmd, \"gpu-assign-qtype\", gpu_assign_qtype)\n",
                "if cpu_tensors_max_size:\n",
                "    add_flag(cmd, \"cpu-tensors-max-size\", cpu_tensors_max_size)\n",
                "if gpu_tensors_max_size:\n",
                "    add_flag(cmd, \"gpu-tensors-max-size\", gpu_tensors_max_size)\n",
                "add_flag(cmd, \"exponential-factor\", exponential_factor)\n",
                "add_flag(cmd, \"debug\", debug)\n",
                "add_flag(cmd, \"info\", info)\n",
                "add_flag(cmd, \"ignore-f32\", ignore_f32)\n",
                "add_flag(cmd, \"no-fallback\", no_fallback)\n",
                "add_flag(cmd, \"tensors-from-csv\", tensors_from_csv)\n",
                "add_flag(cmd, \"skip-gpg\", skip_gpg)\n",
                "\n",
                "add_list_flag(cmd, \"cpu-tensors\", cpu_tensors)\n",
                "add_list_flag(cmd, \"gpu-tensors\", gpu_tensors)\n",
                "add_list_flag(cmd, \"cpu-quants\", cpu_quants)\n",
                "add_list_flag(cmd, \"gpu-quants\", gpu_quants)\n",
                "add_list_flag(cmd, \"cpu-assign-tensors\", cpu_assign_tensors)\n",
                "add_list_flag(cmd, \"gpu-assign-tensors\", gpu_assign_tensors)\n",
                "\n",
                "if harmonize_tensors or harmonize_tensors == []:\n",
                "    if harmonize_tensors == []:\n",
                "        add_list_of_list_flag(cmd, \"harmonize-tensors\", harmonize_tensors, allow_empty=True)\n",
                "    else:\n",
                "        add_list_of_list_flag(cmd, \"harmonize-tensors\", harmonize_tensors)\n",
                "if harmonization_technique or harmonization_technique == 0:\n",
                "    add_flag(cmd, \"harmonization-technique\", harmonization_technique)\n",
                "\n",
                "# Print for verification\n",
                "print(\"\\nRunning quant_assign.py command:\")\n",
                "print(\" \".join(shlex.quote(c) for c in cmd))\n",
                "\n",
                "# Run quant_assign.py\n",
                "result = subprocess.run(cmd, capture_output=True, text=True)\n",
                "\n",
                "# Print stderr and stdout for debugging\n",
                "print(\"quant_assign.py stdout:\", result.stdout)\n",
                "print(\"quant_assign.py stderr:\", result.stderr)\n",
                "\n",
                "if result.returncode != 0:\n",
                "    print(\"quant_assign.py failed:\", result.stderr)\n",
                "    raise SystemExit(1)\n",
                "\n",
                "# Merge regex\n",
                "merge_cmd = [\n",
                "    \"bash\", \"../../quants_regex_merger.sh\",\n",
                "    \"--add-ppl\", \"0\"\n",
                "]\n",
                "if model_name:  # Checks for not None and not empty\n",
                "    merge_cmd += [\"--model-name\", model_name]\n",
                "if model_link:\n",
                "    merge_cmd += [\"--model-link\", model_link]\n",
                "merge = subprocess.run(merge_cmd, input=result.stdout, capture_output=True, text=True)\n",
                "\n",
                "# Print final output\n",
                "print(merge.stdout)\n",
                "\n",
                "if merge.returncode != 0:\n",
                "    print(\"quants_regex_merger.sh failed\")\n",
                "    raise SystemExit(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "637edb2d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "from google.colab import files\n",
                "\n",
                "# List all .recipe files matching the prefix\n",
                "recipe_files = glob.glob(f\"{model_name}*.recipe\")\n",
                "\n",
                "# Print the found files\n",
                "print(\"Downloading .recipe file:\")\n",
                "for file in recipe_files:\n",
                "    print(f\"- {file}\")\n",
                "\n",
                "# Auto‚Äëstart download\n",
                "for file in recipe_files:\n",
                "    files.download(file)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
